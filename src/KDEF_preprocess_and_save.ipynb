{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Augments and saves KDEF Data to Preprocessed Folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running this notebook will:\n",
    "- firstly create a pd dataframe with emotion labels and img paths for KDEF data\n",
    "- augment and save to training/validation/test folders with an equal number of samples per emotion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: KDEF basically has the same number of images per class, so you can just run this notebook to directly split and save the data into the Preprocessed data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset download instructions - do this before running notebook\n",
    "\n",
    "- KDEF dataset: https://www.kdef.se/?fbclid=IwAR102R1eWOMWp87LQK83DDGRsNVLvofz1DdV6TtCGl5tFivNmo3KzEbJc84\n",
    "Download 'KDEF_and_AKDEF' from above link, and put it under '../FER_Resnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import os, os.path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.ndimage\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_KDEF(file_name):\n",
    "    \"\"\"Returns the label of KDEF image given its file name\n",
    "    Args: file_name is a string of the full name of the file, e.g.\"AF03DIFL.JPG\"\n",
    "    \"\"\"\n",
    "    emos = {\n",
    "        \"AN\": \"0\", # anger\n",
    "        \"DI\": \"1\", # disgusted\n",
    "        \"AF\": \"2\", # fear\n",
    "        \"HA\": \"3\" , # happy\n",
    "        \"SA\": \"4\" , # sad\n",
    "        \"SU\": \"5\" , # surprise\n",
    "        \"NE\": \"6\" , # neutral\n",
    "                }\n",
    "    return emos[str(file_name[4:6])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_label_KDEF(\"AF03DIFL.JPG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize a \"black image\" to see what the np values are like\n",
    "- Note: black images are supposed to have all 0 entries, but this doesn't seem to be the case with our images\n",
    "- We can manually delete all the iamges that are \"black\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './KDEF_and_AKDEF/KDEF/AF01/AF01SUFR.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ced56f08be1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Black image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./KDEF_and_AKDEF/KDEF/AF01/AF01SUFR.JPG\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimg_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yuxua\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2877\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2878\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2879\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './KDEF_and_AKDEF/KDEF/AF01/AF01SUFR.JPG'"
     ]
    }
   ],
   "source": [
    "# Black image\n",
    "img = Image.open(\"./KDEF_and_AKDEF/KDEF/AF01/AF01SUFR.JPG\")\n",
    "img_array = np.asarray(img)\n",
    "print(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[143 127 101]\n",
      "  [144 128 102]\n",
      "  [149 132 104]\n",
      "  ...\n",
      "  [144 129 108]\n",
      "  [147 131 108]\n",
      "  [146 130 107]]\n",
      "\n",
      " [[145 129 103]\n",
      "  [141 125  99]\n",
      "  [146 129 101]\n",
      "  ...\n",
      "  [141 126 103]\n",
      "  [139 123 100]\n",
      "  [140 124 101]]\n",
      "\n",
      " [[147 131 105]\n",
      "  [143 127 101]\n",
      "  [147 130 102]\n",
      "  ...\n",
      "  [140 125 102]\n",
      "  [140 125 102]\n",
      "  [142 127 104]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 85  71  62]\n",
      "  [ 78  64  55]\n",
      "  [ 76  62  53]\n",
      "  ...\n",
      "  [123 107  84]\n",
      "  [125 105  81]\n",
      "  [122 102  77]]\n",
      "\n",
      " [[ 91  77  68]\n",
      "  [ 87  73  64]\n",
      "  [ 85  71  62]\n",
      "  ...\n",
      "  [119 103  80]\n",
      "  [121 101  77]\n",
      "  [122 100  77]]\n",
      "\n",
      " [[ 90  76  67]\n",
      "  [ 87  73  64]\n",
      "  [ 87  73  64]\n",
      "  ...\n",
      "  [123 107  84]\n",
      "  [124 103  82]\n",
      "  [125 103  80]]]\n",
      "shape: (762, 562, 3)\n"
     ]
    }
   ],
   "source": [
    "# Non-black image\n",
    "\n",
    "img = Image.open(\"./KDEF_and_AKDEF/KDEF/AF01/AF01AFFR.JPG\")\n",
    "img_array = np.asarray(img)\n",
    "print(img_array)\n",
    "print('shape:',img_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually delete \"black images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified: './KDEF_and_AKDEF/KDEF/BM24/BM24DIFL.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-0df005014311>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mblack_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"BM24DIFL\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'BM22DIHL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'BM21DIFL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AM34DIFR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AM25DIFL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AM20DIHL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AF11NEHL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AF10AFFR'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'AF01SUFR'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mblack_imgs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./KDEF_and_AKDEF/KDEF/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.JPG'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Successfully deleted black images\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified: './KDEF_and_AKDEF/KDEF/BM24/BM24DIFL.JPG'"
     ]
    }
   ],
   "source": [
    "black_imgs = [\"BM24DIFL\",'BM22DIHL','BM21DIFL','AM34DIFR','AM25DIFL','AM20DIHL','AF11NEHL','AF10AFFR','AF01SUFR']\n",
    "for img in black_imgs:\n",
    "    os.remove('./KDEF_and_AKDEF/KDEF/' + img[0:4] + '/' + img + '.JPG')\n",
    "print(\"Successfully deleted black images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe of KDEF images. Columns are emotion labels and img paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_KDEF_df(sideview, halfside, straight):\n",
    "    \"\"\"\n",
    "    Loads all relevant images into a dataframe consisting of emotion label and the image path.\n",
    "\n",
    "    Args:\n",
    "        sideview: True/False, includes datasets that are the full left/right profiles\n",
    "        halfside: True/False, includes datasets that are the half left/right profiles\n",
    "        straight: True/False, includes datasets that are a straight profile\n",
    "    \"\"\"\n",
    "    \n",
    "    KDEF_df = pd.DataFrame(columns=[\"emotion\", \"img_path\"])\n",
    "    \n",
    "    # Path to KDEF folder\n",
    "    KDEF_path = './KDEF_and_AKDEF/KDEF/'\n",
    "        \n",
    "    # initialize df row counter\n",
    "    row = 0\n",
    "        \n",
    "    # Iterate through KDEF folder and append jpgs and their labels to the KDEF dataframe\n",
    "    for folder in os.listdir(KDEF_path):\n",
    "        path = KDEF_path + str(folder)\n",
    "        \n",
    "        for filename in os.listdir(path):\n",
    "            \n",
    "            if (filename.endswith('FL.JPG') or filename.endswith('FR.JPG')) and sideview==True:\n",
    "                KDEF_df.loc[row] = [get_label_KDEF(filename), path + '/' + filename]\n",
    "                \n",
    "            elif (filename.endswith('HR.JPG') or filename.endswith('HL.JPG')) and halfside==True:\n",
    "                KDEF_df.loc[row] = [get_label_KDEF(filename), path + '/' + filename]\n",
    "                    \n",
    "            elif filename.endswith('S.JPG') and straight==True:\n",
    "                KDEF_df.loc[row] = [get_label_KDEF(filename), path + '/' + filename]\n",
    "                \n",
    "            row += 1\n",
    "                    \n",
    "    return KDEF_df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDEF_df = get_KDEF_df(sideview=False, halfside=True, straight=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    420\n",
       "2    420\n",
       "0    420\n",
       "4    419\n",
       "6    419\n",
       "5    419\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KDEF_df = KDEF_df[KDEF_df.emotion != '1']\n",
    "KDEF_df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2517, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KDEF_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion                                           2\n",
      "img_path    ./KDEF_and_AKDEF/KDEF/AF01/AF01AFHL.JPG\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(KDEF_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotion                                          5\n",
      "img_path    ./KDEF_and_AKDEF/KDEF/BM35/BM35SUS.JPG\n",
      "Name: 4890, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(KDEF_df.iloc[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment KDEF images and save to train/validate/test folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Reads and resizes an image from the mux dataset to 48 x 48\n",
    "Also makes it grayscale\n",
    "'''\n",
    "\n",
    "def read_and_resize(img_path, plot_img):   \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img_path: relative path to the KDEF image\n",
    "        \n",
    "    Returns: the resized image as numpy array\n",
    "    \"\"\" \n",
    "    # Read and resize image with OpenCV \n",
    "    img_pixels = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2GRAY) # cv2 reads in BGR, need to convert to grayscale\n",
    "\n",
    "    # Perform a crop so that the image is square i.e. 560x560\n",
    "    crop_img = np.asarray(img_pixels[100:660, 0:560])\n",
    "    \n",
    "    # Resize to 48 x 48\n",
    "    crop_img = cv2.resize(crop_img, dsize=(48, 48), interpolation=cv2.INTER_CUBIC)\n",
    "    img_data = np.asarray(crop_img)\n",
    "    \n",
    "    # Plot if plot_img = True\n",
    "    #if plot_img == True:\n",
    "        #plt.imshow(crop_img)\n",
    "        #cv2.imshow(\"Converted Image\",crop_img)\n",
    "        #print(\"img array shape:\",crop_img.shape)\n",
    "        #cv2.waitKey(0)\n",
    "           \n",
    "    return img_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133, 131, 128, ..., 127, 129, 130],\n",
       "       [129, 132, 133, ..., 128, 132, 130],\n",
       "       [130, 136, 129, ..., 132, 128, 130],\n",
       "       ...,\n",
       "       [  8,   9,   9, ..., 114, 111, 117],\n",
       "       [  6,   8,   9, ..., 114, 112, 115],\n",
       "       [  9,  10,   8, ..., 115, 109, 115]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_and_resize(img_path=\"./KDEF_and_AKDEF/KDEF/AF01/AF01AFFR.JPG\", plot_img = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Returns an array of images as 3 pytorch tensors: [Original, Flipped, Rotated by 5 degrees]\n",
    "'''\n",
    "\n",
    "def augument(img):\n",
    "    \n",
    "    # Original Image and Add RGB channels\n",
    "    img_tensor = torch.from_numpy(np.copy(img)).unsqueeze(0).repeat(3,1,1)\n",
    "    # Rotate Image and add RGB channels\n",
    "    img_rotated_tensor = torch.from_numpy(scipy.ndimage.rotate(np.copy(img), 5, order=1, reshape=False)).unsqueeze(0).repeat(3,1,1)\n",
    "    # Flip image and add RGB channels\n",
    "    img_flipped_tensor = (torch.from_numpy(np.fliplr(np.copy(img)).copy())).repeat(3,1,1)\n",
    "    \n",
    "    return [img_tensor, img_rotated_tensor, img_flipped_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_save(df, total_images):\n",
    "    \n",
    "    \"\"\"\n",
    "    Preprocesses and saves KDEF data to the preprocessed data directory. Splits into train/validate/test and ensures equal \n",
    "    number of samples per class are saved for the KDEF dataset.\n",
    "    \n",
    "    Images are saved as \"KDEF\" + <integer> + <augmentation>\n",
    "\n",
    "    Args: \n",
    "        KDEF dataframe created above\n",
    "        total_images = number of images per class\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Paths to save processed tensor\n",
    "    train_path = './ProcessedNoCutoffData/train/' \n",
    "    val_path = './ProcessedNoCutoffData/validate/' \n",
    "    test_path = './ProcessedNoCutoffData/test/' \n",
    "    \n",
    "    # Check if the save paths exist, make them if they don't\n",
    "    if not os.path.isdir(train_path):\n",
    "        os.mkdir(train_path)\n",
    "    if not os.path.isdir(val_path):\n",
    "        os.mkdir(val_path)\n",
    "    if not os.path.isdir(test_path):\n",
    "        os.mkdir(test_path)\n",
    "        \n",
    "    # Decides when to save to which folder\n",
    "    train_count = (total_images * 0.7)               \n",
    "    val_count = train_count + total_images * 0.15    \n",
    "    test_count = total_images\n",
    "    \n",
    "    # Current count - counts how many images in each class have been saved currently\n",
    "    # First 70% saves to train_path, next 15% saves to val_path, next 15% saves to test path\n",
    "    count = [0, 0, 0, 0, 0, 0, 0]\n",
    "    \n",
    "    num_imgs = len(df.index)\n",
    "    \n",
    "    for i in range(num_imgs):\n",
    "        \n",
    "        # retrieve img path \n",
    "        img_path = df.iloc[i][\"img_path\"]    \n",
    "        \n",
    "        # crop/resize to 48x48\n",
    "        img_data = read_and_resize(img_path,plot_img=False)\n",
    "        \n",
    "        # Normalize to between 0 and 1\n",
    "        img_data = img_data/255   # Since values are in (0, 255)\n",
    "        \n",
    "        # Augument: Add RGB, Flip, Rotate\n",
    "        # Returns 3 tensors\n",
    "        augumented_images = augument(img_data)\n",
    "        emotion = df.iloc[i][\"emotion\"]\n",
    "        \n",
    "        # Decide whether to save to train, val, or test\n",
    "        if(count[int(emotion)] < train_count):\n",
    "            folder_name = train_path + str(emotion)\n",
    "        elif(count[int(emotion)] < val_count):\n",
    "            folder_name = val_path + str(emotion)\n",
    "        elif(count[int(emotion)] < test_count):\n",
    "            folder_name = test_path + str(emotion)\n",
    "        \n",
    "        # Save if total images for emotion is less than total images\n",
    "        if(count[int(emotion)] < total_images):\n",
    "            \n",
    "            # Create directory for emotion if it doesn't already exist\n",
    "            if not os.path.isdir(folder_name):\n",
    "                os.mkdir(folder_name)\n",
    "\n",
    "            # Save original and augmented images\n",
    "            torch.save(augumented_images[0], folder_name + '/KDEF' + str(i) + '.tensor')\n",
    "            torch.save(augumented_images[1], folder_name + '/KDEF' + str(i) + '_rotated.tensor')\n",
    "            torch.save(augumented_images[2], folder_name + '/KDEF' + str(i) + '_flipped.tensor')\n",
    "            count[int(emotion)] += 3\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_and_save(df=KDEF_df, total_images=1257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
